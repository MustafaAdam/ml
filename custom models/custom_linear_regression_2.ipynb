{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55db653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "      .notes-container {\n",
       "        font-family: Arial, sans-serif;\n",
       "        color: #333;\n",
       "        line-height: 1.6;\n",
       "        text-align: left;\n",
       "      }\n",
       "      .notes-container h1 {\n",
       "        color: #3498db;\n",
       "        border-bottom: 2px solid #3498db;\n",
       "        padding-bottom: 10px;\n",
       "        margin: 0;\n",
       "        text-align: left;\n",
       "      }\n",
       "      .note-box {\n",
       "        background-color: #f8f9fa;\n",
       "        padding: 20px;\n",
       "        border-radius: 8px;\n",
       "        margin: 20px 0;\n",
       "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
       "        width: 100%;\n",
       "      }\n",
       "      .highlight-box {\n",
       "        background-color: #e8f4f8;\n",
       "        padding: 15px;\n",
       "        border-left: 4px solid #3498db;\n",
       "        border-radius: 4px;\n",
       "      }\n",
       "      .highlight-box strong {\n",
       "        color: #3498db;\n",
       "        display: block;\n",
       "        margin-top: 5px;\n",
       "      }\n",
       "      .code-block {\n",
       "        margin: 8px 0;\n",
       "        font-family: 'Courier New', monospace;\n",
       "        font-size: 25px;\n",
       "        padding: 10px;\n",
       "        border-radius: 4px;\n",
       "        overflow-x: auto;\n",
       "      }\n",
       "      .note-description {\n",
       "        font-size: 14px;\n",
       "        color: #555;\n",
       "        margin-top: 5px;\n",
       "      }\n",
       "      .highlight-text {\n",
       "        color: #ee5d6c;\n",
       "      }\n",
       "      .highlight-heading {\n",
       "        color: #3498db;\n",
       "      }\n",
       "      ul {\n",
       "        padding-left: 20px;\n",
       "        margin: 0;\n",
       "        text-align: left;\n",
       "      }\n",
       "      li {\n",
       "        text-align: left;\n",
       "      }\n",
       "    </style>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def load_styles():\n",
    "    styles_and_html = \"\"\"\n",
    "    <style>\n",
    "      .notes-container {\n",
    "        font-family: Arial, sans-serif;\n",
    "        color: #333;\n",
    "        line-height: 1.6;\n",
    "        text-align: left;\n",
    "      }\n",
    "      .notes-container h1 {\n",
    "        color: #3498db;\n",
    "        border-bottom: 2px solid #3498db;\n",
    "        padding-bottom: 10px;\n",
    "        margin: 0;\n",
    "        text-align: left;\n",
    "      }\n",
    "      .note-box {\n",
    "        background-color: #f8f9fa;\n",
    "        padding: 20px;\n",
    "        border-radius: 8px;\n",
    "        margin: 20px 0;\n",
    "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        width: 100%;\n",
    "      }\n",
    "      .highlight-box {\n",
    "        background-color: #e8f4f8;\n",
    "        padding: 15px;\n",
    "        border-left: 4px solid #3498db;\n",
    "        border-radius: 4px;\n",
    "      }\n",
    "      .highlight-box strong {\n",
    "        color: #3498db;\n",
    "        display: block;\n",
    "        margin-top: 5px;\n",
    "      }\n",
    "      .code-block {\n",
    "        margin: 8px 0;\n",
    "        font-family: 'Courier New', monospace;\n",
    "        font-size: 25px;\n",
    "        padding: 10px;\n",
    "        border-radius: 4px;\n",
    "        overflow-x: auto;\n",
    "      }\n",
    "      .note-description {\n",
    "        font-size: 14px;\n",
    "        color: #555;\n",
    "        margin-top: 5px;\n",
    "      }\n",
    "      .highlight-text {\n",
    "        color: #ee5d6c;\n",
    "      }\n",
    "      .highlight-heading {\n",
    "        color: #3498db;\n",
    "      }\n",
    "      ul {\n",
    "        padding-left: 20px;\n",
    "        margin: 0;\n",
    "        text-align: left;\n",
    "      }\n",
    "      li {\n",
    "        text-align: left;\n",
    "      }\n",
    "      h1 {\n",
    "        color: #3498db !important;\n",
    "        border-bottom: 2px solid #3498db !important;\n",
    "        padding-bottom: 10px !important;\n",
    "        margin: 0 0 10px 0 !important;\n",
    "        text-align: left !important;\n",
    "        font-family: Arial, sans-serif !important;\n",
    "      }\n",
    "    </style>\n",
    "\n",
    "    \"\"\"\n",
    "    display(HTML(styles_and_html))\n",
    "\n",
    "load_styles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c997a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e5c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.13176519,  0.        , 81.08849711,  0.        , 47.54299311])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "true_bias = -15\n",
    "features, target, true_weights = make_regression(n_features=5,\n",
    "                coef=True,\n",
    "                n_informative=3,\n",
    "                bias=true_bias,\n",
    "                n_samples=30000,\n",
    "                random_state=42,\n",
    "                )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02780e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinearRegression:\n",
    "    def __init__(self, number_of_iterations=1000, learning_rate=0.1,\n",
    "                regularize=False, regularization_strength=1, regularization_type='l2'):\n",
    "        self.weights : np.ndarray = None  # (n_features, )\n",
    "        self.bias : float = None  # scalar \n",
    "        self.number_of_iterations : int = number_of_iterations\n",
    "        self.learning_rate : float = learning_rate\n",
    "        self.cost_history : list[float] = []\n",
    "        self.regularize = regularize\n",
    "        self.regularization_strength = regularization_strength\n",
    "        self.regularization_type = regularization_type\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def _compute_loss(self, true_values, predicted_values) -> float:\n",
    "    # the difference between the the true values (y) and the predicted values (y_hat)\n",
    "        errors = true_values - predicted_values\n",
    "        \n",
    "        squared_errors = np.square(errors)  # square the errors\n",
    "        mean_squared_error = np.mean(squared_errors)  # sum the squared error then divide by number of samples\n",
    "    \n",
    "        # if user chooses to regularize\n",
    "        if self.regularize and self.regularization_type == 'l2':\n",
    "            # number of samples\n",
    "            m = true_values.shape[0]\n",
    "            \n",
    "            weights_squared = np.square(self.weights)\n",
    "            sum_weights_squared = np.sum(weights_squared)\n",
    "            \n",
    "            l2_penalty = (self.regularization_strength / m) * sum_weights_squared\n",
    "            return 1/2 * (mean_squared_error + l2_penalty)\n",
    "    \n",
    "        elif self.regularize and self.regularization_type == 'l1':\n",
    "            m = true_values.shape[0]\n",
    "            \n",
    "            weights_absolute_values = np.abs(self.weights)\n",
    "            sum_absolute_values = np.sum(weights_absolute_values)\n",
    "            \n",
    "            l1_penalty = (self.regularization_strength / m) * sum_absolute_values\n",
    "            return 1/2 * (mean_squared_error + l1_penalty)\n",
    "            \n",
    "        # if user does not choose to regularize\n",
    "        else:\n",
    "            return 1/2 * mean_squared_error\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def _forward_propagation(self, input_matrix, true_values):\n",
    "        y_hat = input_matrix @ self.weights + self.bias  # predictions of the model using current weights and bias\n",
    "        cost = self._compute_loss(true_values, y_hat)    # cost of the current predictions and the true values \n",
    "        self.cost_history.append(cost)                   # add the current cost the list of costs \n",
    "        return y_hat                                     # return the current predictions and the current cost\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def _backward_propagation(self, feature_matrix, true_values, predicted_values):\n",
    "        number_of_samples = feature_matrix.shape[0]\n",
    "        error = predicted_values - true_values\n",
    "    \n",
    "        # notice that bias is not regularized (no l1 or l2 terms)\n",
    "        bias_derivative = np.mean(error)\n",
    "    \n",
    "        # weights gradient without regulariztion\n",
    "        unregularized_weights_gradient = 1 / number_of_samples * (feature_matrix.T @ error)\n",
    "    \n",
    "        # add L2 regularization if enabled\n",
    "        if self.regularize and self.regularization_type == 'l2':\n",
    "            l2_penalty = (self.regularization_strength / number_of_samples) * self.weights\n",
    "            weights_gradient = unregularized_weights_gradient + l2_penalty\n",
    "            return weights_gradient, bias_derivative\n",
    "\n",
    "        # add L1 regularization if enable\n",
    "        elif self.regularize and self.regularization_type == 'l1':\n",
    "            l1_penalty = (self.regularization_strength / number_of_samples) * np.sign(self.weights)\n",
    "            weights_gradient = unregularized_weights_gradient + l1_penalty\n",
    "            return weights_gradient, bias_derivative\n",
    "            \n",
    "        # without any regularization\n",
    "        else:\n",
    "            # note that weights_gradient == unregularized_term if no regularization is applied\n",
    "            weights_gradient = unregularized_weights_gradient\n",
    "            return weights_gradient, bias_derivative\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def _update(self, weights_gradient, bias_derivative):\n",
    "        if self.regularize and self.regularization_type == 'l1':\n",
    "            # Gradient descent step without regularization term included, \n",
    "            # because regularization is handled by proximal step below\n",
    "            temp_weights = self.weights - (self.learning_rate * weights_gradient)\n",
    "            # Soft-thresholding (proximal operator)\n",
    "            threshold = self.learning_rate * self.regularization_strength / len(temp_weights)  # or number_of_samples\n",
    "            \n",
    "            self.weights = np.sign(temp_weights) * np.maximum(np.abs(temp_weights) - threshold, 0)\n",
    "            self.bias = self.bias - (self.learning_rate * bias_derivative)\n",
    "        else:\n",
    "            self.weights = self.weights - (self.learning_rate * weights_gradient)\n",
    "            self.bias = self.bias - (self.learning_rate * bias_derivative)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def _init_parameters(self, n_features):\n",
    "        self.weights = np.random.normal(0.0, 0.01, size=n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._init_parameters(X.shape[1])\n",
    "\n",
    "        for iteration in range(self.number_of_iterations):\n",
    "            y_hat = self._forward_propagation(X, y)\n",
    "            weights_derivative, bias_derivative = self._backward_propagation(X, y, y_hat)\n",
    "            self._update(weights_derivative, bias_derivative)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = X @ self.weights + self.bias\n",
    "        return predictions\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def plot_losses(self, ax=None):\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "        \n",
    "        sns.lineplot(self.cost_history, label=f'Final cost: {self.cost_history[-1]:.5f}', ax=ax)\n",
    "        ax.set_xlabel('Iterations')\n",
    "        ax.set_ylabel('Cost')\n",
    "        ax.set_title('Training Cost Vs Iteration')\n",
    "        ax.grid()\n",
    "        ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
